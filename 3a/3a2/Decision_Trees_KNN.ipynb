{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas_profiling import ProfileReport\n",
    "\n",
    "#from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE \n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spliting data into known and unknown labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data/raw_data/data.csv', header=None)\n",
    "labels = pd.read_csv('./data/raw_data/labels.csv', header=None)\n",
    "\n",
    "data_labelled = data[:len(labels.index)]\n",
    "data_unlabelled = data[len(labels.index):]\n",
    "\n",
    "data_labelled.to_csv('./data/processed_data/known_labels.csv')\n",
    "data_unlabelled.to_csv('./data/processed_data/unknown_labels.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge known labels dataframe with the respective labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labels.rename(columns={0: 'y'})\n",
    "df = pd.concat([data_labelled, labels], axis=1)\n",
    "\n",
    "df['y'] = df['y'].map({1: False, 2: True})\n",
    "\n",
    "df.to_csv('./data/processed_data/data_with_labels.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class ratio and null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class ratio:\n",
      " 1    156\n",
      "2     23\n",
      "Name: y, dtype: int64\n",
      "Columns with null values:\n",
      " []\n"
     ]
    }
   ],
   "source": [
    "print('Class ratio:\\n', labels['y'].value_counts())\n",
    "print('Columns with null values:\\n', df.columns[df.isna().any()].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like theres a high class imbalance however no columns have null values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a vizualization html page to vizualize feature destribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# profile = ProfileReport(df, minimal=True)\n",
    "# profile.to_file(\"visualization/output.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets just try out a simple decision tree without much pre-processing to have a baseline performance metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining which metrics to monitor\n",
    "scoring = ['f1','accuracy','precision','recall']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Max depth should be one of the main parameters to tune, given that the deeper the tree is, the more likely it is to overfit and perform badly on unseen data. We'll use a **5 fold cross validation** for are all experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 38 candidates, totalling 190 fits\n",
      "Best parameters:\n",
      " {'model__criterion': 'gini', 'model__max_depth': 2}\n",
      "Best f1 score:\n",
      " 0.9713164068729908\n"
     ]
    }
   ],
   "source": [
    "baseline_tree_pipeline = Pipeline([('model',DecisionTreeClassifier(random_state=42))])\n",
    "\n",
    "baseline_tree_search = GridSearchCV(\n",
    "    estimator = baseline_tree_pipeline,\n",
    "    param_grid = {\n",
    "        'model__criterion':['gini','entropy'],\n",
    "        'model__max_depth':range(1,20),\n",
    "    },\n",
    "    scoring=scoring,\n",
    "    refit='f1',\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "baseline_tree_search.fit(data_labelled,labels.values.ravel())\n",
    "\n",
    "print('Best parameters:\\n', baseline_tree_search.best_params_)\n",
    "print('Best f1 score:\\n',baseline_tree_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANOVA + SMOTE Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From our exploratory analysis it seems like ANOVA and Relief work the best. Lets start with using ANOVA classification to get the top n features and apply SMOTE to try and combat the class imbalance but creating new instances of the rarest class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "improved_tree_pipeline = Pipeline(\n",
    "    [\n",
    "     ('selector',SelectKBest(f_classif)),\n",
    "     ('smote',SMOTE(random_state=42)),\n",
    "     ('model',DecisionTreeClassifier(random_state=42))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "improved_tree_search = GridSearchCV(\n",
    "    estimator = improved_tree_pipeline,\n",
    "    param_grid = {\n",
    "        'selector__k':[5,10,15,20,30,40,50],\n",
    "        'model__criterion':['gini','entropy'],\n",
    "        'model__max_depth':range(1,20),\n",
    "    },\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    scoring='f1',\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 266 candidates, totalling 1330 fits\n",
      "Best parameters:\n",
      " {'model__criterion': 'entropy', 'model__max_depth': 5, 'selector__k': 5}\n",
      "Best f1 score:\n",
      " 0.9811492673992674\n"
     ]
    }
   ],
   "source": [
    "improved_tree_search.fit(data_labelled,labels.values.ravel())\n",
    "\n",
    "decision_tree_best = improved_tree_search.best_estimator_\n",
    "\n",
    "print('Best parameters:\\n', improved_tree_search.best_params_)\n",
    "print('Best f1 score:\\n',improved_tree_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like the decision tree performs best with a max_depth set to 5 while choosing the top 5 features from the ANOVA analysis. Limiting the depth of the tree helps with having better performance since we're running CV and it punishes trees that overfit with a higher max depth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbors "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as we did with Decision Trees we'll first create a baseline KNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "Best parameters:\n",
      " {'model__metric': 'euclidean', 'model__n_neighbors': 1, 'model__weights': 'uniform'}\n",
      "Best f1 score:\n",
      " 0.9595192307692308\n"
     ]
    }
   ],
   "source": [
    "baseline_knn_pipeline = Pipeline([('model',KNeighborsClassifier())])\n",
    "\n",
    "baseline_knn_search = GridSearchCV(\n",
    "    estimator = baseline_knn_pipeline,\n",
    "    param_grid = {\n",
    "    'model__weights':['uniform','distance'],\n",
    "    'model__n_neighbors':[1,3,5,7,9],\n",
    "    'model__metric':['euclidean','manhattan','chebyshev','minkowski']\n",
    "    },\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    scoring='f1',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "baseline_knn_search.fit(data_labelled,labels.values.ravel())\n",
    "\n",
    "print('Best parameters:\\n', baseline_knn_search.best_params_)\n",
    "print('Best f1 score:\\n',baseline_knn_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got worse results that our previous tree perhaps because KNN relies on using a distance function between features and we didn't use a feauture scaler. Let's use a feature scaller as the first step on our pipeline followed by SMOTE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "improved_knn_pipeline = Pipeline(\n",
    "    [('scaller',StandardScaler()),\n",
    "     ('selector',SelectKBest(f_classif)),\n",
    "     ('smote',SMOTE(random_state=42)),\n",
    "     ('model',KNeighborsClassifier())\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "improved_knn_search = GridSearchCV(\n",
    "    estimator = improved_knn_pipeline,\n",
    "    param_grid = {'selector__k':[5,10,15,20,30,40,50],\n",
    "    'model__weights':['uniform','distance'],\n",
    "    'model__n_neighbors':[1,3,5,7,9],\n",
    "    'model__metric':['euclidean','manhattan','chebyshev','minkowski']\n",
    "    },\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    scoring='f1',\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 280 candidates, totalling 1400 fits\n",
      "Best parameters:\n",
      " {'model__metric': 'chebyshev', 'model__n_neighbors': 7, 'model__weights': 'uniform', 'selector__k': 40}\n",
      "Best f1 score:\n",
      " 0.9937484737484737\n"
     ]
    }
   ],
   "source": [
    "improved_knn_search.fit(data_labelled,labels.values.ravel())\n",
    "\n",
    "knn_best = improved_knn_search.best_estimator_\n",
    "\n",
    "print('Best parameters:\\n', improved_knn_search.best_params_)\n",
    "print('Best f1 score:\\n',improved_knn_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying a standart scaller and using feature upsampling made a big difference in the performance of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN reveals to have better performance than Decision Trees measuring by the f1 score. Interesting to note that here KNN tends to perform better with more features, given that the best results come from using the top 40 in comparison to the top 5 in the decision tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our own ensemble classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create our own ensemble model we'll use the best performing model of each categafory we've tested so far: Decision Trees and KNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators=[('decision_tree', decision_tree_best), ('knn', knn_best)]\n",
    "# voting set to hard so that majority wins\n",
    "ensemble = VotingClassifier(estimators, voting='hard')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4410 candidates, totalling 22050 fits\n",
      "Best parameters:\n",
      " {'model__criterion': 'gini', 'model__max_depth': 5, 'model__min_samples_leaf': 1, 'model__min_samples_split': 2, 'model__n_estimators': 500, 'selector__k': 50}\n",
      "Best f1 score:\n",
      " 0.9842261904761905\n"
     ]
    }
   ],
   "source": [
    "random_forest_pipeline = Pipeline(\n",
    "    [('selector',SelectKBest(f_classif)),\n",
    "     ('smote',SMOTE(random_state=42)),\n",
    "     ('model',RandomForestClassifier(random_state=42))]\n",
    ")\n",
    "\n",
    "random_forest_search = GridSearchCV(\n",
    "    estimator = random_forest_pipeline,\n",
    "    param_grid = {\n",
    "        'selector__k':[5,10,15,20,50],\n",
    "        'model__criterion':['gini','entropy'],\n",
    "        'model__max_depth':[2,5,10,20],\n",
    "        'model__min_samples_split':range(2,10),\n",
    "        'model__min_samples_leaf': [1, 2, 4],\n",
    "        'model__min_samples_split': [2, 5, 10],\n",
    "        'model__n_estimators':[50,100,200,500]\n",
    "    },\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    scoring='f1',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "random_forest_search.fit(data_labelled,labels.values.ravel())\n",
    "\n",
    "random_forest_best = random_forest_search.best_estimator_\n",
    "\n",
    "print('Best parameters:\\n', random_forest_search.best_params_)\n",
    "print('Best f1 score:\\n',random_forest_search.best_score_)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cc5ccfa982ac0c806d028cc5c3bc1fe8554eb246e53476722f6c4c66d9ffd506"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

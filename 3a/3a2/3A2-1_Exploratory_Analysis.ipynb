{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "varying-jacket",
   "metadata": {},
   "source": [
    "# Initial Data Analysis for 3A\n",
    "\n",
    "First, the necesary imports. \n",
    "If Matplotlib does not want to display plots, install a GUI backend such as pyqt5 (available over pip) or tkinter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "configured-nickname",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "from statistics import median\n",
    "from preprocessing.relief import relief\n",
    "from scipy.stats import f_oneway, zscore\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternate-picking",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [10, 7] # Change the desired figure size here if it is needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alone-canadian",
   "metadata": {},
   "source": [
    "Replace the following paths with the paths of the data.csv and labels.csv file on your system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "behavioral-consumption",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/raw_data/data.csv\", header= None)\n",
    "labels = pd.read_csv(\"./data/raw_data/labels.csv\", header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thirty-hypothesis",
   "metadata": {},
   "source": [
    "We extract the indices of the two present classes for later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prescribed-yield",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_indices_class_1 = labels.index[labels[0] == 1]\n",
    "orig_indices_class_2 = labels.index[labels[0] == 2]    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "communist-patent",
   "metadata": {},
   "source": [
    "Let's take a look at the ranges of the various features to see if they are comparable (relevant for kNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sought-therapy",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranges = [max(df[i]) - min(df[i]) for i in range(0, df.shape[1])]\n",
    "print(f\"Max range of a feature at feature {np.argmax(ranges)}, range: {max(ranges)}\")\n",
    "print(f\"Min range of a feature at feature {np.argmin(ranges)}, range: {min(ranges)}\")\n",
    "print(f\"Median range: {median(ranges)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contained-temperature",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(sorted(ranges, reverse=True))\n",
    "plt.xlabel(\"Features\")\n",
    "plt.ylabel(\"Range in feature\")\n",
    "plt.title(\"Feature range from largest to smallest\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dramatic-earthquake",
   "metadata": {},
   "source": [
    "Next, we take a look at how the classes are balanced in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "awful-seafood",
   "metadata": {},
   "outputs": [],
   "source": [
    "balance = labels[0].value_counts()\n",
    "print(balance)\n",
    "y_pos = np.arange(2)\n",
    "plt.bar(y_pos, [balance[1], balance[2]], width=0.6)\n",
    "plt.xticks(y_pos, (\"Class 1\", \"Class 2\"))\n",
    "plt.ylabel(\"Data points\")\n",
    "plt.title(\"Number of data points for each class\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amber-moral",
   "metadata": {},
   "source": [
    "Unfortunately, it seems the dataset is quite unbalanced."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elegant-sheep",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stupid-leeds",
   "metadata": {},
   "source": [
    "Next, we'll try an exploratory PCA to see how the PCs relate to the explained variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "invalid-danish",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=df.shape[1])\n",
    "pca.fit(df)\n",
    "cum_explained = np.cumsum(pca.explained_variance_ratio_)\n",
    "plt.plot(cum_explained)\n",
    "plt.xlabel(\"# of Principal Components included\")\n",
    "plt.ylabel(\"Cumulative variance explained\")\n",
    "plt.title(\"Cumulative variance explained by PCs\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recorded-carnival",
   "metadata": {},
   "source": [
    "Neat, it seems like PCA works relatively well. How well?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protected-edwards",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"PCs needed to explain variance:\")\n",
    "print(f\">=90% of variance explained at PC: {np.argmax(cum_explained>=0.9)}\")\n",
    "print(f\">=95% of variance explained at PC: {np.argmax(cum_explained>=0.95)}\")\n",
    "print(f\">=99% of variance explained at PC: {np.argmax(cum_explained >= 0.99)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instant-appreciation",
   "metadata": {},
   "source": [
    "Lets restrict the number of dimensions to 3 for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contained-particle",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca3 = PCA(n_components=3)\n",
    "pca3.fit(df)\n",
    "data_pca3 = pd.DataFrame(pca3.transform(df))\n",
    "\n",
    "print(f\"Variance explained by the first 3 PCs: {sum(pca3.explained_variance_ratio_)}\")\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [14, 10]\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection=\"3d\")\n",
    "\n",
    "points_class_1 = data_pca3.iloc[orig_indices_class_1]\n",
    "points_class_2 = data_pca3.iloc[orig_indices_class_2]\n",
    "\n",
    "ax.scatter(points_class_1[0], points_class_1[1], points_class_1[2], color='b', marker='o', label=\"Class 1\")\n",
    "ax.scatter(points_class_2[0], points_class_2[1], points_class_2[2], color='r', marker='^', label=\"Class 2\")\n",
    "\n",
    "ax.set_xlabel(\"PC 1\")\n",
    "ax.set_ylabel(\"PC 2\")\n",
    "ax.set_zlabel(\"PC 3\")\n",
    "ax.set_title(\"Labelled data projected to the first 3 PCs\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "athletic-bibliography",
   "metadata": {},
   "source": [
    "One last interesting visualisation is to see how the data from the unlabelled set is distributed over this space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specific-yellow",
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabelled_data = data_pca3.iloc[labels.shape[0]:, :]\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [14, 10]\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection=\"3d\")\n",
    "\n",
    "ax.scatter(unlabelled_data[0], unlabelled_data[1], unlabelled_data[2], color='g', marker = 'x')\n",
    "\n",
    "ax.set_xlabel(\"PC 1\")\n",
    "ax.set_ylabel(\"PC 2\")\n",
    "ax.set_zlabel(\"PC 2\")\n",
    "ax.set_title(\"Unlabelled data projected to the first 3 PCs\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collaborative-white",
   "metadata": {},
   "source": [
    "## ANOVA\n",
    "\n",
    "We will perform anova for each feature, and see which features differ the most between groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informal-quilt",
   "metadata": {},
   "outputs": [],
   "source": [
    "def anova(data:pd.DataFrame, indices_class_1:list, indices_class_2:list):\n",
    "    \n",
    "\n",
    "    pvals = []\n",
    "\n",
    "    dps_c1 = data.iloc[indices_class_1]\n",
    "    dps_c2 = data.iloc[indices_class_2]\n",
    "\n",
    "    for feature_idx in range(data.shape[1]):\n",
    "        c1_feature = dps_c1.iloc[:, feature_idx]\n",
    "        c2_feature = dps_c2.iloc[:, feature_idx]\n",
    "    \n",
    "        f = f_oneway(c1_feature, c2_feature)\n",
    "        pvals.append(f.pvalue)\n",
    "\n",
    "    feature_indices = list(range(df.shape[1]))\n",
    "    \n",
    "    return zip(*sorted(zip(pvals, feature_indices)))\n",
    "\n",
    "sorted_pvals, sorted_feature_indices = anova(df, orig_indices_class_1, orig_indices_class_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "executed-contrast",
   "metadata": {},
   "source": [
    "Lets see how many of these features return a significant difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disabled-teddy",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_significant = sum(v < 0.05 for v in sorted_pvals)\n",
    "print(num_significant)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satellite-rwanda",
   "metadata": {},
   "source": [
    "Quite a lot. What if we check for a lower p-value (*** level)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accessible-powell",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_significant = sum(v < 0.001 for v in sorted_pvals)\n",
    "print(num_significant)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "saved-labor",
   "metadata": {},
   "source": [
    "Still quite a few. For visualisation, we will show the first 10 or so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "auburn-gates",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_best_anova_1 = []\n",
    "data_best_anova_2 = []\n",
    "\n",
    "dps_c1 = df.iloc[orig_indices_class_1]\n",
    "dps_c2 = df.iloc[orig_indices_class_2]\n",
    "feature_indices = list(range(df.shape[1]))\n",
    "\n",
    "for i in range(10):\n",
    "    data_best_anova_1.append(dps_c1[feature_indices[i]])\n",
    "    data_best_anova_2.append(dps_c2[feature_indices[i]])\n",
    "\n",
    "# We change the size due to all the data\n",
    "plt.rcParams['figure.figsize'] = [17, 12]\n",
    "    \n",
    "c = \"blue\"\n",
    "plt.boxplot(data_best_anova_1, positions=list(range(1,11)), widths=0.3, patch_artist=True, \n",
    "            boxprops=dict(facecolor=c, color=c), capprops=dict(color=c),\n",
    "            whiskerprops=dict(color=c), flierprops=dict(color=c, markeredgecolor=c), medianprops=dict(color=c))\n",
    "\n",
    "c = \"red\"\n",
    "plt.boxplot(data_best_anova_2, positions=[0.5 + i for i in range(1, 11)], widths=0.3, patch_artist=True, \n",
    "            boxprops=dict(facecolor=c, color=c), capprops=dict(color=c),\n",
    "            whiskerprops=dict(color=c), flierprops=dict(color=c, markeredgecolor=c), medianprops=dict(color=c))\n",
    "\n",
    "y_pos = [0.25 + i for i in range(1, 11)]\n",
    "plt.xticks(y_pos, [f\"Feature {i}\" for i in sorted_feature_indices[:10]])\n",
    "\n",
    "plt.ylabel(\"Feature values\")\n",
    "plt.xlabel(\"From left to right, most signicant differences between class features\")\n",
    "\n",
    "#Custom legend as matplotlib does not support labelling the way I'd like\n",
    "legend_els = [Patch(facecolor='b', edgecolor='b', label='Class 1'), \n",
    "                Patch(facecolor='r', edgecolor='r',label='Class 2')]\n",
    "\n",
    "\n",
    "plt.legend(handles=legend_els, loc=\"best\")\n",
    "\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "existing-netherlands",
   "metadata": {},
   "source": [
    "# T-SNE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atlantic-celtic",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tsne3d(data: pd.DataFrame, indices_class_1, indices_class_2, title: str):\n",
    "    plt.rcParams['figure.figsize'] = [14, 10]\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(projection=\"3d\")\n",
    "    \n",
    "    points_class_1 = data.iloc[indices_class_1]\n",
    "    points_class_2 = data.iloc[indices_class_2]\n",
    "    \n",
    "    ax.scatter(points_class_1[0], points_class_1[1], points_class_1[2], color='b', marker='o', label=\"Class 1\")\n",
    "    ax.scatter(points_class_2[0], points_class_2[1], points_class_2[2], color='r', marker='^', label=\"Class 2\")\n",
    "    \n",
    "    ax.set_xlabel(\"t-SNE dimension 1\")\n",
    "    ax.set_ylabel(\"t-SNE dimension 2\")\n",
    "    ax.set_zlabel(\"t-SNE dimension 3\")\n",
    "    ax.set_title(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "tsne = pd.DataFrame(TSNE(n_components=3, learning_rate='auto', init='random').fit_transform(df))\n",
    "plot_tsne3d(tsne, orig_indices_class_1, orig_indices_class_2, \"Labelled data projected to the 3D t-SNE space\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "present-recall",
   "metadata": {},
   "source": [
    "It seems that T-SNE can separate these points relatively well, in two islands."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nuclear-error",
   "metadata": {},
   "source": [
    "# Impact of pre-processing methods\n",
    "\n",
    "In this section we will evaluate the effect of various methods of pre-processing on the ability to separate the data using t-SNE. \n",
    "\n",
    "## Pre-processing without upsampling\n",
    "\n",
    "### PCA with 9 leading eigenvectors ($\\geq$95% of variance explained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "square-cleanup",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca9 = PCA(n_components=9)\n",
    "data_pca9 = pd.DataFrame(pca9.fit_transform(df))\n",
    "\n",
    "tsne = pd.DataFrame(TSNE(n_components=3, learning_rate='auto', init='random').fit_transform(data_pca9))\n",
    "plot_tsne3d(tsne, orig_indices_class_1, orig_indices_class_2, \"Labelled data projected to the 3D t-SNE space after a PCA-transform\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rural-richardson",
   "metadata": {},
   "source": [
    "It seems like the separation is slightly better, the red points have been projected much more outward.\n",
    "\n",
    "### Z-Transformed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mobile-clinton",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.copy()\n",
    "df2.apply(zscore)\n",
    "\n",
    "tsne = pd.DataFrame(TSNE(n_components=3, learning_rate='auto', init='random').fit_transform(df2))\n",
    "plot_tsne3d(tsne, orig_indices_class_1, orig_indices_class_2, \"Labelled data projected to the 3D t-SNE space after a z-transform\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "golden-gravity",
   "metadata": {},
   "source": [
    "### Feature selection using ANOVA\n",
    "We have previously found which features differ the most significantly according to ANOVA. So perhaps we can only use those for t-SNE? As above, we'll use the features whose difference in means was at least of a significance level ***."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intimate-bidder",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df2 = df.iloc[:,list(sorted_feature_indices[:73])]\n",
    "\n",
    "tsne = pd.DataFrame(TSNE(n_components=3, learning_rate='auto', init='random').fit_transform(df2))\n",
    "plot_tsne3d(tsne, orig_indices_class_1, orig_indices_class_2, \"Labelled data projected to the 3D t-SNE space after feature selection using ANOVA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ignored-fraction",
   "metadata": {},
   "source": [
    "### Feature selection using Relief\n",
    "We use a self-written relief function to perform the relief algorithm and then we analyse the results.\n",
    "Minor precaution: This makes your computer work somewhat, so don't worry if it does not finish for a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "potential-being",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = relief(df, labels, labels.shape[0])\n",
    "print(f\"Most relevant weight: {max(w)}\")\n",
    "print(f\"Median weight: {median(w)}\")\n",
    "\n",
    "sorted_weights, sorted_feature_weight_indices = zip(*sorted(zip(w, list(range(df.shape[1]))), reverse=True))\n",
    "\n",
    "comp = pd.DataFrame()\n",
    "comp['most_relevant_features_relief'] = sorted_feature_weight_indices[:10]\n",
    "comp['most_relevant_features_ANOVA'] = sorted_feature_indices[:10]\n",
    "\n",
    "comp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modular-ability",
   "metadata": {},
   "source": [
    "Interestingly, there are only 2 features in common between the two methods in the top 10. Let's try t-SNE using only these dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assured-testing",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df2 = df.iloc[:,list(sorted_feature_weight_indices[:10])]\n",
    "\n",
    "tsne = pd.DataFrame(TSNE(n_components=3, learning_rate='auto', init='random').fit_transform(df2))\n",
    "plot_tsne3d(tsne, orig_indices_class_1, orig_indices_class_2, \"Labelled data projected to the 3D t-SNE space after feature selection using Relief\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "furnished-offer",
   "metadata": {},
   "source": [
    "What if we combine these top 10s?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acceptable-metabolism",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "indices = list(set(sorted_feature_weight_indices[:10]).union(set(sorted_feature_indices[:73])))\n",
    "df2 = df.iloc[:,indices]\n",
    "\n",
    "tsne = pd.DataFrame(TSNE(n_components=3, learning_rate='auto', init='random').fit_transform(df2))\n",
    "plot_tsne3d(tsne, orig_indices_class_1, orig_indices_class_2, \"Labelled data projected to the 3D t-SNE space after feature selection using Relief and ANOVA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bored-mainland",
   "metadata": {},
   "source": [
    "## Pre-processing after upsampling\n",
    "We will balance our data using SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acceptable-library",
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample = SMOTE()\n",
    "df_upsampled, labels_upsampled = oversample.fit_resample(df.iloc[:labels.shape[0],:], labels)\n",
    "\n",
    "upsample_indices_class_1 = labels_upsampled.index[labels_upsampled[0] == 1]\n",
    "upsample_indices_class_2 = labels_upsampled.index[labels_upsampled[0] == 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floral-header",
   "metadata": {},
   "source": [
    "### Base-line: Upsampling without further processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demographic-request",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = pd.DataFrame(TSNE(n_components=3, learning_rate='auto', init='random').fit_transform(df_upsampled))\n",
    "plot_tsne3d(tsne, upsample_indices_class_1, upsample_indices_class_2, \"Labelled data projected to the 3D t-SNE space after a PCA-transform\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liked-china",
   "metadata": {},
   "source": [
    "### PCA with 9 leading eigenvectors ($\\geq$95% of variance explained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expired-cologne",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca9 = PCA(n_components=9)\n",
    "data_pca9 = pd.DataFrame(pca9.fit_transform(df_upsampled))\n",
    "\n",
    "tsne = pd.DataFrame(TSNE(n_components=3, learning_rate='auto', init='random').fit_transform(data_pca9))\n",
    "plot_tsne3d(tsne, upsample_indices_class_1, upsample_indices_class_2, \"Labelled data projected to the 3D t-SNE space after a PCA-transform\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subsequent-monster",
   "metadata": {},
   "source": [
    "### Z-transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprised-corner",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df_upsampled.copy()\n",
    "df2.apply(zscore)\n",
    "\n",
    "tsne = pd.DataFrame(TSNE(n_components=3, learning_rate='auto', init='random').fit_transform(df2))\n",
    "plot_tsne3d(tsne, upsample_indices_class_1, upsample_indices_class_2, \"Labelled data projected to the 3D t-SNE space after a z-transform\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "going-expert",
   "metadata": {},
   "source": [
    "### ANOVA: based on previous selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sized-electronics",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df_upsampled.iloc[:,list(sorted_feature_indices[:73])]\n",
    "\n",
    "tsne = pd.DataFrame(TSNE(n_components=3, learning_rate='auto', init='random').fit_transform(df2))\n",
    "plot_tsne3d(tsne, upsample_indices_class_1, upsample_indices_class_2, \"Labelled data projected to the 3D t-SNE space after feature selection using ANOVA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gorgeous-plenty",
   "metadata": {},
   "source": [
    "### ANOVA: Applied to the new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "close-juice",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_pvals_up, sorted_feature_indices_up = anova(df_upsampled, upsample_indices_class_1, upsample_indices_class_2)\n",
    "\n",
    "num_significant = sum(v < 0.001 for v in sorted_pvals_up)\n",
    "print(num_significant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moderate-mistress",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df_upsampled.iloc[:,list(sorted_feature_indices[:num_significant])]\n",
    "\n",
    "tsne = pd.DataFrame(TSNE(n_components=3, learning_rate='auto', init='random').fit_transform(df2))\n",
    "plot_tsne3d(tsne, upsample_indices_class_1, upsample_indices_class_2, \"Labelled data projected to the 3D t-SNE space after feature selection using ANOVA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "retired-parks",
   "metadata": {},
   "source": [
    "It might be interesting to see how the top 10 best features differ between ANOVA prior to upsampling and after."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caroline-lease",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp = pd.DataFrame()\n",
    "comp['most_relevant_features_anova'] = sorted_feature_indices[:10]\n",
    "comp['most_relevant_features_anova_up'] = sorted_feature_indices_up[:10]\n",
    "\n",
    "comp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "medical-armenia",
   "metadata": {},
   "source": [
    "Similar for half of the list. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "approximate-semiconductor",
   "metadata": {},
   "source": [
    "### Relief\n",
    "\n",
    "Note: This will take even longer than before as the time complexity of relief is unfortunately quadratic if we use all points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "individual-attendance",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = relief(df_upsampled, labels_upsampled, labels_upsampled.shape[0])\n",
    "print(f\"Most relevant weight: {max(w)}\")\n",
    "print(f\"Median weight: {median(w)}\")\n",
    "\n",
    "sorted_weights_up, sorted_feature_weight_indices_up = zip(*sorted(zip(w, list(range(df.shape[1]))), reverse=True))\n",
    "\n",
    "comp = pd.DataFrame()\n",
    "comp['most_relevant_features_relief'] = sorted_feature_weight_indices[:10]\n",
    "comp['most_relevant_features_relief_up'] = sorted_feature_weight_indices_up[:10]\n",
    "\n",
    "comp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fuzzy-conviction",
   "metadata": {},
   "source": [
    "4 matches between the relief approach prior to upsampling, and after upsampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sweet-fishing",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df_upsampled.iloc[:,list(sorted_feature_weight_indices_up[:10])]\n",
    "\n",
    "tsne = pd.DataFrame(TSNE(n_components=3, learning_rate='auto', init='random').fit_transform(df2))\n",
    "plot_tsne3d(tsne, upsample_indices_class_1, upsample_indices_class_2, \"Labelled data projected to the 3D t-SNE space after feature selection using Relief\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rocky-coordinate",
   "metadata": {},
   "source": [
    "And now, a combination again between the features from ANOVA and Relief:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "living-notion",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = list(set(sorted_feature_weight_indices_up[:10]).union(set(sorted_feature_indices_up[:73])))\n",
    "print(len(indices))\n",
    "df2 = df_upsampled.iloc[:,indices]\n",
    "\n",
    "tsne = pd.DataFrame(TSNE(n_components=3, learning_rate='auto', init='random').fit_transform(df2))\n",
    "plot_tsne3d(tsne, upsample_indices_class_1, upsample_indices_class_2, \"Labelled data projected to the 3D t-SNE space after feature selection using Relief and ANOVA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "talented-duncan",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "skilled-laugh",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
